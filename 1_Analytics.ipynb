{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd55377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from connections import * \n",
    "import boto3\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cc7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aqui faço um for para listar os arquivos recebidos e carregar os seus nomes em uma lista\n",
    "\"\"\"\n",
    "for _,_, files in os.walk(conns_paths.sources):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc27b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Nesta célula há a iteração da lista de nomes dos arquivos visando carregá-los para dataframe\n",
    "'''\n",
    "files_list = list()\n",
    "for f in files:    \n",
    "    df = 'df_'+str(f)[:str(f).find('.')].strip(\"[|'|\\\"\")\n",
    "    files_list.append(df)\n",
    "    prog = f\"{df} = pd.read_csv('{conns_paths.sources}/{f}',sep=';',encoding='utf8')\"\n",
    "    exec(prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2410bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Estas linhas comentadas foram usadas para reconhecimento das colunas disponíveis em cada arquivo\n",
    "para que fosse feito o merge necessário entre os dataframes.\n",
    "'''\n",
    "# Merge this on a Dimtable apart!! df_categories_columns = ['category_id', 'category_name', 'description', 'picture']\n",
    "# df_customers_columns = ['customer_id', 'company_name', 'contact_name', 'contact_title','address', 'city', 'region', 'postal_code', 'country', 'phone', 'fax']\n",
    "# df_employees_columns = ['employee_id', 'last_name', 'first_name', 'title', 'title_of_courtesy','birth_date', 'hire_date', 'address', 'city', 'region', 'postal_code','country', 'home_phone', 'extension', 'photo', 'notes', 'reports_to','photo_path']\n",
    "# Dont merge this on Fact!!! df_employee_territories_columns = ['employee_id', 'territory_id']\n",
    "# df_orders.columns = ['order_id', 'customer_id', 'employee_id', 'order_date', 'required_date','shipped_date', 'ship_via', 'freight', 'ship_name', 'ship_address','ship_city', 'ship_region', 'ship_postal_code', 'ship_country']\n",
    "# df_order_details_columns  = ['order_id', 'product_id', 'unit_price', 'quantity', 'discount']\n",
    "# df_products_columns = ['product_id', 'product_name', 'supplier_id', 'category_id','quantity_per_unit', 'unit_price', 'units_in_stock', 'units_on_order','reorder_level', 'discontinued']\n",
    "# Merge this on a table apart!! df_region_columns = ['region_id', 'region_description']\n",
    "# df_shippers_columns = ['shipper_id', 'company_name', 'phone']\n",
    "# Merge this on a Dimtable apart!! df_suppliers_columns = ['supplier_id', 'company_name', 'contact_name', 'contact_title','address', 'city', 'region', 'postal_code', 'country', 'phone', 'fax','homepage']\n",
    "# Merge this on a Dimtable apart!! df_territories_columns = ['territory_id', 'territory_description', 'region_id']\n",
    "# Merge this on a Dimtable apart!! df_us_states_columns = ['state_id', 'state_name', 'state_abbr', 'state_region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f91467",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Após reconhecimento, pude entender como os dataframes se relacionam, e aqui fiz o merge.\n",
    "'''\n",
    "\n",
    "fact = df_orders.merge(df_order_details,left_on='order_id',right_on='order_id',how='left')\\\n",
    ".merge(df_customers,left_on='customer_id',right_on='customer_id',how='left')\\\n",
    ".merge(df_shippers,left_on='ship_via',right_on='shipper_id',how='left')\\\n",
    ".merge(df_employees,left_on='employee_id',right_on='employee_id',how='left')\\\n",
    ".merge(df_products,left_on='product_id',right_on='product_id',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aqui listei os campos, que a primeira vista, julguei desnecessários para a análise.\n",
    "\n",
    "'''\n",
    "\n",
    "# FactAvailableColumns = ['order_id', 'customer_id', 'employee_id', 'order_date', 'required_date',\n",
    "#        'shipped_date', 'ship_via', 'freight', 'ship_name', 'ship_address',\n",
    "#        'ship_city', 'ship_region', 'ship_postal_code', 'ship_country',\n",
    "#        'product_id', 'unit_price_x', 'quantity', 'discount', 'company_name_x',\n",
    "#        'contact_name', 'contact_title', 'address_x', 'city_x', 'region_x',\n",
    "#        'postal_code_x', 'country_x', 'phone_x', 'fax', 'shipper_id',\n",
    "#        'company_name_y', 'phone_y', 'last_name', 'first_name', 'title',\n",
    "#        'title_of_courtesy', 'birth_date', 'hire_date', 'address_y', 'city_y',\n",
    "#        'region_y', 'postal_code_y', 'country_y', 'home_phone', 'extension',\n",
    "#        'photo', 'notes', 'reports_to', 'photo_path', 'product_name',\n",
    "#        'supplier_id', 'category_id', 'quantity_per_unit', 'unit_price_y',\n",
    "#        'units_in_stock', 'units_on_order', 'reorder_level', 'discontinued']\n",
    "\n",
    "columns_to_drop = ['contact_name', 'contact_title', 'address_x','postal_code_x','phone_y', 'last_name', 'first_name', 'title','title_of_courtesy','birth_date','address_y', 'city_y','postal_code_y', 'country_y', 'home_phone', 'extension','photo', 'notes','photo_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f443dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aqui retirei as colunas e ordenei o dataframe por customer id e order date\n",
    "'''\n",
    "fact = fact.drop(columns=columns_to_drop)\n",
    "fact = fact.sort_values(['customer_id','order_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90232051",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Aqui carrego o dataframe com as colunas necessarias para csv em pasta local'''\n",
    "fact.to_csv(conns_paths.datalakesources+'/Fact.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2686c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Nesta célula carrego o dataframe para o S3\n",
    "'''\n",
    "for _,_, datalakefiles in os.walk(conns_paths.datalakesources):\n",
    "    pass\n",
    "\n",
    "\n",
    "# aqui falta terminar for para carregar o s3\n",
    "s3_client = boto3.client('s3')\n",
    "# \"s3_client.upload_file(f'{conns_paths.datalakesources}/{dlf}',{connections.bucket},f/\"landing/{dlf}\\\")\"\n",
    "\n",
    "for dlf in datalakefiles:    \n",
    "    load_dl = f's3_client.upload_file(\"{conns_paths.datalakesources}/{dlf}\",\"{conns_paths.bucket}\",\"{conns_paths.landing}{dlf}\")'\n",
    "    exec(load_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
